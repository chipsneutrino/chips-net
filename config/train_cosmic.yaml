task: "train"  # What is the task? (create, train, study)
exp:
    name: "cosmic"  # Name of experiment
    output_dir: "./data/models/"  # Path to model output experiment directory
    comet: False  # Should we use comet to store the experiment online
data:
    input_dirs:  # The directories from which to take input data
        - "./data/input/chips_1200/flux/"
        - "./data/input/chips_1200/cosmic/"
    unstack: True  # Should we split the channels into seperate images?
    #channels: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  # Active channels
    channels: [1, 1, 1]  # Active channels
    augment: True  # Should we enable random and shifting augmentation to the images?
    rand: [.02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02, .02]
    shift: [.0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0, .0]
    cat_select: -1  # Choose a singular t_all_cat category to train on, used for energy networks (-1 = don't choose)
    img_size: [64, 64]  # The input image size
model: 
    type: "vgg"  # (vgg, resnet, inception)
    labels: ["t_cosmic_cat"]  # For cosmic classifier
    lr: 0.0002  # The initial learning rate
    lr_decay: 0.5  # Learning rate decay coefficient
    dense_units: 512  # Number of units to use in dense layers
    dropout: 0.2  # Dropout rate to use in dropout layers
    filters: 64  # Initial number of filters to use
    reco_pars: True  # Should the reco paramters be appended to final dense layer?
    bottleneck: False  # Should we use the bottleneck resnet variant?
    se_ratio: 16  # Ratio for squeeze-exitation blocks, if zero they will not be used
    learn_weights: False  # If training multiple labels, should we use the custom weight learning layer?
    precision_policy: "float32"  # Should we use mixed precision 'mixed_float16' or normal 'float32'
    summarise: True  # Should we display a summary of the model when it is built?
trainer:
    train_examples: 256000  # Number of training examples to use
    val_examples: 64000  # Number of validation examples to use
    test_examples: 64000  # Nqumber of testing examples to use
    batch_size: 128  # Training batch size
    epochs: 10  # Number of epochs to train for
    tb_update: 1000  # How often should tensorboard record values (batches)
    steps_per_epoch: -1  # Number of steps per epoch (-1 default)
    es_monitor: "val_accuracy"  # Metric to monitor for early stopping
    es_delta: 0.00001  # Early stopping minimum delta value
    es_epochs: 2  # Early stopping epochs without delta change before stop
    
